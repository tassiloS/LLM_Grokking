# ðŸš€ Grokking
### ðŸ“š MVA LLM Course Final Project

GENERALIZATION BEYOND OVERFITTING ON SMALL ALGORITHMIC DATASETS

Testing the grokking phenomenon described in https://arxiv.org/pdf/2201.02177 using the TP1 arithmetic dataset

### ðŸ‘¥ Authors
- Tassilo Schallenberg: tassilo.schallenberg@gmail.com

- Michel Doroch: michel.doroch@ens-paris-saclay.fr

- ClÃ©ment Tisseau: clement.tisseau@gmail.com

### ðŸ”— [View Slides](https://drive.google.com/file/d/1HP0I7yzwoI8syhchfj4DfRhV9TbU3aXO/view?usp=sharing)


## ðŸ”Ž Research Overview

-	Exploration of the grokking phenomenon across a variety of arithmetic operations.

-	Experiments with different model architectures, including both Transformers and lighter non-Transformer (MLP-based) models.

-	Study of recent advances in accelerating grokking, focusing on techniques such as Grokfast and Grokking as the Transition from Lazy to Rich Training Dynamics.


## ðŸ“– References 
- **Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets**  
  Alethea Power, Yuri Burda, Harri Edwards, Igor Babuschkin, Vedant Misra.  
  [arXiv:2201.02177](https://arxiv.org/abs/2201.02177)

- **Towards Understanding Grokking: An Effective Theory of Representation Learning**  
  Ziming Liu, Ouail Kitouni, Niklas Nolte, Eric J. Michaud, Max Tegmark, Mike Williams.  
  [arXiv:2205.10343](https://arxiv.org/abs/2205.10343)

- **Progress measures for grokking via mechanistic interpretability**  
  Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, Jacob Steinhardt.  
  [arXiv:2301.05217](https://arxiv.org/abs/2301.05217)